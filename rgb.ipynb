{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/deepmind/kinetics-i3d/files/3879458/convert_to_flow.ipynb.zip\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_IMAGE_SIZE = 256\n",
    "\n",
    "def cal_for_frames(video_path): # frame/test_rgb/\n",
    "    frames = glob(os.path.join(video_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "\n",
    "    flow = []\n",
    "    prev = cv2.imread(frames[0])\n",
    "    prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    prev = cv2.resize(prev,(224,224))\n",
    "    for i, frame_curr in enumerate(frames):\n",
    "        if i%5==0:\n",
    "            curr = cv2.imread(frame_curr)\n",
    "            curr = cv2.resize(curr,(224,224))\n",
    "            curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "            tmp_flow = compute_TVL1(prev, curr)\n",
    "            flow.append(tmp_flow)\n",
    "            prev = curr\n",
    "\n",
    "    return flow\n",
    "\n",
    "def compute_TVL1(prev, curr, bound=15):\n",
    "    \"\"\"Compute the TV-L1 optical flow.\"\"\"\n",
    "    TVL1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = TVL1.calc(prev, curr, None)\n",
    "    flow = np.clip(flow, -20,20) #default values are +20 and -20\n",
    "    #print(flow)\n",
    "    assert flow.dtype == np.float32\n",
    "\n",
    "    flow = (flow + bound) * (255.0 / (2*bound))\n",
    "    flow = np.round(flow).astype(int)\n",
    "    flow[flow >= 255] = 255\n",
    "    flow[flow <= 0] = 0\n",
    "\n",
    "    return flow\n",
    "\n",
    "# def save_flow(video_flows, flow_path): # flow, test/test_flow/\n",
    "def save_flow(video_flows): # flow, test/test_flow/\n",
    "    # The optical flows are generated in 3D. However for I3D only first two channels are used. u is the first channel\n",
    "    # and v is the second channel. Both u and v are saved in separate folders in the flow_path directory.\n",
    "    # The u and v folders will be generated by calling create_path() function\n",
    "    n_py=[]\n",
    "    for i, flow in enumerate(video_flows):\n",
    "        # dont save\n",
    "        # cv2.imwrite(os.path.join(flow_path.format('u'), \"{:06d}.jpg\".format(i)), flow[:, :, 0])\n",
    "        # cv2.imwrite(os.path.join(flow_path.format('v'), \"{:06d}.jpg\".format(i)), flow[:, :, 1])\n",
    "        n_py.append(np.dstack([flow[:, :, 0],flow[:, :, 1]]))\n",
    "    return n_py\n",
    "\n",
    "def extract_flow(args):\n",
    "    video_path, flow_path = args\n",
    "    flow = cal_for_frames(video_path)\n",
    "    save_flow(flow, flow_path)\n",
    "    print('complete:' + flow_path)\n",
    "    return\n",
    "\n",
    "def create_paths(base_path):\n",
    "    # activity_path = os.path.join(base_path, activity) # train/activity\n",
    "    # rgb_folder = os.makedirs('{}/{}_rgb'.format(activity_path, activity)) # train/activity/activity_rgb\n",
    "    # flow_folder1 = os.makedirs('{}/{}_flow/u'.format(activity_path, activity)) # train/activity/activity_flow/u\n",
    "    # flow_folder2 = os.makedirs('{}/{}_flow/v'.format(activity_path, activity)) # train/activity/activity_flow/v\n",
    "    save_folder = os.path.join(base_path, \"output\")\n",
    "    src_folder = os.path.join(base_path, \"src\")\n",
    "    c_lists = glob(os.path.join(src_folder,\"*\"))\n",
    "    for cls in c_lists:\n",
    "        # v_lists = glob(os.path.join(cls,\"*\"))\n",
    "        cls_name = cls.split(\"/\")[-1]\n",
    "\n",
    "        flow_dir = save_folder + \"/flow/\" + cls_name\n",
    "        frame_dir = save_folder + \"/frame/\" + cls_name\n",
    "        npyflow_dir = save_folder + \"/npyflow/\" + cls_name\n",
    "        rgb_dir = save_folder + \"/rgb/\" + cls_name\n",
    "\n",
    "        os.mkdir(flow_dir)\n",
    "        os.mkdir(frame_dir)\n",
    "        os.mkdir(npyflow_dir)\n",
    "        os.mkdir(rgb_dir)\n",
    "\n",
    "        v_lists = glob(os.path.join(cls, \"*\"))\n",
    "        for v in v_lists:\n",
    "            video = v.split(\"/\")[-1][:-4]\n",
    "            os.mkdir(os.path.join(flow_dir, video))\n",
    "            os.mkdir(os.path.join(frame_dir, video))\n",
    "            os.mkdir(os.path.join(npyflow_dir, video))\n",
    "            os.mkdir(os.path.join(rgb_dir, video))\n",
    "\n",
    "def vid_to_image(video_path, frame_path):\n",
    "    print(\"video path:\", video_path)\n",
    "    print(\"frame path:\", frame_path)\n",
    "\n",
    "    cls_lists = glob(os.path.join(video_path, \"*\"))\n",
    "    print(\"cls lists:\", cls_lists)\n",
    "    for cls in cls_lists:\n",
    "        cls_name = cls.split(\"/\")[-1]\n",
    "        save_dir = os.path.join(frame_path, cls_name)\n",
    "\n",
    "        v_lists = glob(os.path.join(cls, \"*\"))\n",
    "        for v in v_lists:\n",
    "            vid_name = v.split(\"/\")[-1][:-4]\n",
    "            vidcap = cv2.VideoCapture(v)\n",
    "            success, image = vidcap.read()\n",
    "            count = 0\n",
    "            frame_no = 0\n",
    "            print(\"save frame path:\", os.path.join(save_dir, vid_name))\n",
    "            while success:\n",
    "                vidcap.set(1, frame_no)\n",
    "                # print(os.path.join(frame_path,\"frame%d.jpg\"))\n",
    "                cv2.imwrite(os.path.join(os.path.join(save_dir, vid_name), \"frame%d.jpg\") % count, image)  # save frame as JPEG file\n",
    "                success, image = vidcap.read()\n",
    "                # print('Read a new frame: ', success)\n",
    "                count += 1\n",
    "                frame_no += 1\n",
    "\n",
    "    '''\n",
    "    # print(\"base path/file/frame_path\", base_path, file, frame_path)\n",
    "    folder=file.split('.')[0]\n",
    "    #print(folder)\n",
    "    #os.mkdir(os.path.join(base_path,folder))\n",
    "    vidcap = cv2.VideoCapture(file)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_no=0\n",
    "    print(\"frame path:\", frame_path)\n",
    "    while success:\n",
    "            vidcap.set(1,frame_no)\n",
    "            #print(os.path.join(frame_path,\"frame%d.jpg\"))\n",
    "            cv2.imwrite(os.path.join(frame_path,\"frame%d.jpg\") % count, image)     # save frame as JPEG file\n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "            frame_no+=1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create npy file for rgb files as described in deepmind I3D\n",
    "def norm_rgb(rgb_path, nchannel):\n",
    "    # print(video_path)\n",
    "    npy_file = []\n",
    "    frames = glob(os.path.join(rgb_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "    # print(len(frames))\n",
    "    # print(\"rgb_path:\", rgb_path)\n",
    "    for i, frame in enumerate(frames):\n",
    "        if i%5==0:\n",
    "            img = cv2.imread(frame)\n",
    "            img_new = (cv2.resize(img, (224, 224))).astype(float)\n",
    "            # img_norm = np.divide(2 * (img_new - img_new.min()), (img_new.max() - img_new.min())) - 1\n",
    "            npy_file.append(img_new)\n",
    "            # npy_file.append(img_norm)\n",
    "\n",
    "    try:\n",
    "        npy_file = np.reshape(np.asarray(npy_file), (1, len(frames)//5, 224, 224, nchannel))\n",
    "    except:\n",
    "        npy_file = np.reshape(np.asarray(npy_file), (1, len(frames)//5+1, 224, 224, nchannel))\n",
    "    return npy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls lists: ['/home/hdd1/data/extract/src/sleeping', '/home/hdd1/data/extract/src/laughing', '/home/hdd1/data/extract/src/smoking', '/home/hdd1/data/extract/src/drinking', '/home/hdd1/data/extract/src/tying', '/home/hdd1/data/extract/src/writing', '/home/hdd1/data/extract/src/winking', '/home/hdd1/data/extract/src/slapping', '/home/hdd1/data/extract/src/smiling', '/home/hdd1/data/extract/src/typing', '/home/hdd1/data/extract/src/driving', '/home/hdd1/data/extract/src/pointing', '/home/hdd1/data/extract/src/crying', '/home/hdd1/data/extract/src/running', '/home/hdd1/data/extract/src/calling', '/home/hdd1/data/extract/src/sitting', '/home/hdd1/data/extract/src/standing', '/home/hdd1/data/extract/src/squinting', '/home/hdd1/data/extract/src/bending', '/home/hdd1/data/extract/src/talking', '/home/hdd1/data/extract/src/walking', '/home/hdd1/data/extract/src/reading', '/home/hdd1/data/extract/src/folding', '/home/hdd1/data/extract/src/frowning'] \n",
      "\n",
      "class: 3/24\tdrinking\n"
     ]
    }
   ],
   "source": [
    "# 4:20\n",
    "if __name__ == \"__main__\":\n",
    "#     01. create class folder\n",
    "    #base_path = \"/home/veryyoung/문서/optical_flow_extractor/extract\"\n",
    "    base_path = \"/home/hdd1/data/extract\"\n",
    "    src_path = os.path.join(base_path, \"src\")\n",
    "    output_path = os.path.join(base_path, \"output\")\n",
    "\n",
    "    cls_lists = glob(os.path.join(src_path, \"*\"))\n",
    "    print(\"cls lists:\", cls_lists, \"\\n\")\n",
    "    \n",
    "    cls_lists.sort()\n",
    "\n",
    "#     02. calculate optical flow\n",
    "\n",
    "#     for i, cls in enumerate(cls_lists):\n",
    "    cls_name = cls.split(\"/\")[-1]\n",
    "    print(\"class: {}/{}\\t{}\".format(i, len(cls_lists), cls_name))\n",
    "    n_cls_path = os.path.join(output_path, cls_name)\n",
    "\n",
    "    video_lists = glob(os.path.join(cls, \"*\"))\n",
    "\n",
    "    v = \"/home/hdd1/data/extract/src/bending/getty-woman-harvesting-cauliflower-on-organic-farm-video-id593422949_5\"\n",
    "\n",
    "#         for j, v in enumerate(video_lists):\n",
    "    vid_name = v.split(\"/\")[-1]\n",
    "    des_path = os.path.join(n_cls_path, vid_name)\n",
    "\n",
    "    # save at each dir\n",
    "    np_file_rgb = norm_rgb(v, 3)\n",
    "#             np.save(des_path + '/rgb.npy', np_file_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_file_rgb.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
